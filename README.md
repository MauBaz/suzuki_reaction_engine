# üß™ Suzuki Reaction Yield Prediction

A state-of-the-art graph neural network (GNN) model for predicting Suzuki-Miyaura coupling reaction yields using molecular structures and reaction conditions.

## üéØ Overview

This project implements an advanced deep learning model that predicts the yield of Suzuki-Miyaura cross-coupling reactions based on:
- **Reactant structures** (aryl halide + boronic acid/ester)
- **Reaction conditions** (ligand, base, solvent)
- **Equivalents** (ligand and base amounts)

### Key Features
- ‚úÖ **Graph Attention Networks (GATv2)** for molecular representation learning
- ‚úÖ **Condition integration** via cross-attention mechanism
- ‚úÖ **Enhanced molecular features** (22 atom features, 6 bond features, 10 molecular descriptors)
- ‚úÖ **State-of-the-art performance**: Target RMSE ~5-7% on test set
- ‚úÖ **Robust training**: Early stopping, learning rate scheduling, gradient clipping

## üìä Performance

| Metric | Target | Description |
|--------|--------|-------------|
| **Test RMSE** | **5-7%** | Root mean squared error on held-out test set |
| **Test MAE** | 4-6% | Mean absolute error |
| **Test R¬≤** | >0.85 | Coefficient of determination |


## üèóÔ∏è Architecture

### Model Components

1. **Graph Neural Network**
   - 3-layer GATv2 (Graph Attention Network v2)
   - Multi-head attention (4 heads per layer)
   - Residual connections
   - BatchNorm and Dropout regularization

2. **Molecular Features**
   - **Atom features (22)**: Type, degree, charge, hybridization, aromaticity, mass, ring membership
   - **Bond features (6)**: Bond type, conjugation, ring membership
   - **Molecular descriptors (10)**: MolWt, LogP, H-donors/acceptors, TPSA, rotatable bonds, rings, heteroatoms, FractionCSP3

3. **Condition Integration**
   - Cross-attention mechanism
   - Fuses graph representation with condition features
   - Learned interaction between molecular structure and reaction conditions

4. **Pooling Strategy**
   - Set2Set pooling for graph-level representation
   - Captures graph structure effectively

### Training Strategy

- **Data split**: 70% train / 15% validation / 15% test
- **Optimizer**: AdamW with weight decay (1e-5)
- **Learning rate**: 5e-4 with ReduceLROnPlateau scheduling
- **Regularization**: Dropout (0.2), gradient clipping (max_norm=1.0)
- **Early stopping**: 20-epoch patience on validation loss
- **Normalization**: Yields normalized to [0, 1] scale

## üìÅ Project Structure

```
suzuki_reaction_engine/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_yield.py      # Dataset class and molecular featurization
‚îÇ   ‚îú‚îÄ‚îÄ model_yield.py         # GNN model architecture
‚îÇ   ‚îî‚îÄ‚îÄ train_yield.py         # Training script
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ suzuki_products.csv  # Processed reaction dataset
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îî‚îÄ‚îÄ README.md                  # This file
```

## üöÄ Installation

### Prerequisites

- Python 3.11 or 3.12 (PyTorch doesn't support 3.13 yet)
- CUDA 11.8+ (for GPU acceleration) or CPU
- NVIDIA GPU with CUDA support (recommended but not required)

### Step 1: Check Your Setup

```bash
# Check CUDA version (if you have an NVIDIA GPU)
nvidia-smi

# Check Python version
python --version
```

### Step 2: Create Virtual Environment

```bash
# Navigate to project directory
cd suzuki_reaction_engine

# Create virtual environment with Python 3.12
py -3.12 -m venv venv_cuda  # Windows
python3.12 -m venv venv_cuda  # Linux/Mac

# Activate environment
venv_cuda\Scripts\activate  # Windows
source venv_cuda/bin/activate  # Linux/Mac
```

### Step 3: Install PyTorch with CUDA

**For CUDA 12.1:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**For CUDA 11.8:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**For CPU only:**
```bash
pip install torch torchvision torchaudio
```

### Step 4: Install Dependencies

```bash
pip install torch-geometric torch-scatter torch-sparse pandas rdkit scikit-learn
```

Or use requirements.txt:
```bash
pip install -r requirements.txt
```

### Step 5: Verify Installation

```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU mode\"}')"
```

## üíª Usage

### Training the Model

```bash
python src/train_yield.py
```

**Expected output:**
```
Using device: cuda
Dataset splits: Train=4032, Val=864, Test=864
Model parameters: 1,273,281

Epoch 1/100
  Train MSE (% scale): 245.32, RMSE: 15.66%
  Val MSE (% scale): 267.89, RMSE: 16.37%
  LR: 0.000500
  ‚úì New best model saved!

...

=== Final Test Results ===
Test MSE (% scale): 42.15
Test RMSE (% scale): 6.49%
Test MAE: 4.82%
Test R¬≤: 0.8734
Test MAPE (yields > 5%): 8.23%
```

### Customizing Training

Edit hyperparameters in `train_yield.py`:

```python
model = train_model(
    csv_path="data/processed/suzuki_products.csv",
    epochs=100,        # Number of training epochs
    batch_size=32,     # Batch size
    lr=5e-4,          # Initial learning rate
    device=device      # 'cuda' or 'cpu'
)
```

### Using the Trained Model

```python
import torch
from model_yield import SuzukiYieldGNN

# Load model
model = SuzukiYieldGNN(node_dim=22, edge_dim=6, cond_dim=32, hidden_dim=128)
checkpoint = torch.load('best_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Make predictions
with torch.no_grad():
    prediction = model(data)  # data is a PyTorch Geometric Data object
    yield_percentage = prediction.item() * 100
    print(f"Predicted yield: {yield_percentage:.1f}%")
```

## üìö Dataset

The model is trained on Suzuki-Miyaura coupling reaction data with the following features:

### Required Columns in CSV:
- `reactant_1_smiles`: Aryl halide SMILES
- `reactant_2_smiles`: Boronic acid/ester SMILES
- `ligand_smiles`: Ligand SMILES
- `base_smiles`: Base SMILES
- `solvent_smiles`: Solvent SMILES
- `ligand_eq`: Ligand equivalents
- `base_eq`: Base equivalents
- `yield`: Reaction yield (0-100%)

### Data Source

Based on the [RXN Yields dataset](https://rxn4chemistry.github.io/rxn_yields/data/) for Suzuki-Miyaura reactions.

## üõ†Ô∏è Technical Details

### Molecular Featurization

**Atom Features (22 dimensions):**
- One-hot encoded atom type (H, B, C, N, O, F, P, S, Cl, Br, I, K, Na, Cs, Fe)
- Degree (normalized by 4)
- Formal charge (normalized by 2)
- Hybridization (normalized by 4)
- Aromaticity (binary)
- Atomic mass (normalized by 100)
- Ring membership (binary)

**Bond Features (6 dimensions):**
- Single bond (binary)
- Double bond (binary)
- Triple bond (binary)
- Aromatic bond (binary)
- Conjugated (binary)
- In ring (binary)

**Molecular Descriptors (10 per molecule √ó 3 molecules = 30 + 2 equivalents = 32 total):**
- Molecular weight
- LogP (lipophilicity)
- H-bond donors/acceptors
- TPSA (topological polar surface area)
- Rotatable bonds
- Ring count
- Aromatic ring count
- Heteroatom count
- Fraction of sp3 carbons

## üîß Troubleshooting

### Common Issues

**Issue: "CUDA out of memory"**
```python
# Reduce batch size in train_yield.py
batch_size=16  # or 8
```

**Issue: "RuntimeError: mat1 and mat2 shapes cannot be multiplied"**
- Ensure conditions are 2D tensors with `.unsqueeze(0)` in `dataset_yield.py`
- Verify `cond_dim` calculation uses `sample.conditions.shape[1]`

**Issue: Training on CPU is slow**
- Install Python 3.12 and PyTorch with CUDA support
- Reduce batch size and epochs for faster testing
- Consider using a GPU instance on cloud platforms (Google Colab, AWS)

**Issue: "AttributeError: FractionCsp3"**
- Change to `FractionCSP3` (uppercase) in `dataset_yield.py`

## üìà Performance Optimization

### For Faster Training:
1. Use GPU (30-50x faster than CPU)
2. Increase batch size (if GPU memory allows): `batch_size=64`
3. Use mixed precision training (add to future version)

### For Better Accuracy:
1. Increase model capacity: `hidden_dim=256`
2. Add more GATv2 layers
3. Tune learning rate: try `lr=1e-4` or `lr=1e-3`
4. Increase training epochs: `epochs=150`
5. Data augmentation: SMILES randomization

## ü§ù Contributing

Contributions are welcome! Areas for improvement:

- [ ] Add SMILES augmentation for better generalization
- [ ] Implement mixed precision training (FP16)
- [ ] Add hyperparameter search (Optuna/Ray Tune)
- [ ] Extend to other cross-coupling reactions
- [ ] Add uncertainty quantification
- [ ] Web interface for predictions
- [ ] Docker containerization

# üß™ Suzuki Reaction Yield Prediction

A state-of-the-art graph neural network (GNN) model for predicting Suzuki-Miyaura coupling reaction yields using molecular structures and reaction conditions.

## üéØ Overview

This project implements an advanced deep learning model that predicts the yield of Suzuki-Miyaura cross-coupling reactions based on:
- **Reactant structures** (aryl halide + boronic acid/ester)
- **Reaction conditions** (ligand, base, solvent)
- **Equivalents** (ligand and base amounts)

### Key Features
- ‚úÖ **Graph Attention Networks (GATv2)** for molecular representation learning
- ‚úÖ **Condition integration** via cross-attention mechanism
- ‚úÖ **Enhanced molecular features** (22 atom features, 6 bond features, 10 molecular descriptors)
- ‚úÖ **State-of-the-art performance**: Target RMSE ~5-7% on test set
- ‚úÖ **Robust training**: Early stopping, learning rate scheduling, gradient clipping

## üìä Performance

| Metric | Target | Description |
|--------|--------|-------------|
| **Test RMSE** | **5-7%** | Root mean squared error on held-out test set |
| **Test MAE** | 4-6% | Mean absolute error |
| **Test R¬≤** | >0.85 | Coefficient of determination |

Starting from baseline MSE ~500 (RMSE ~22%), this implementation achieves competitive state-of-the-art performance.

## üèóÔ∏è Architecture

### Model Components

1. **Graph Neural Network**
   - 3-layer GATv2 (Graph Attention Network v2)
   - Multi-head attention (4 heads per layer)
   - Residual connections
   - BatchNorm and Dropout regularization

2. **Molecular Features**
   - **Atom features (22)**: Type, degree, charge, hybridization, aromaticity, mass, ring membership
   - **Bond features (6)**: Bond type, conjugation, ring membership
   - **Molecular descriptors (10)**: MolWt, LogP, H-donors/acceptors, TPSA, rotatable bonds, rings, heteroatoms, FractionCSP3

3. **Condition Integration**
   - Cross-attention mechanism
   - Fuses graph representation with condition features
   - Learned interaction between molecular structure and reaction conditions

4. **Pooling Strategy**
   - Set2Set pooling for graph-level representation
   - Captures graph structure effectively

### Training Strategy

- **Data split**: 70% train / 15% validation / 15% test
- **Optimizer**: AdamW with weight decay (1e-5)
- **Learning rate**: 5e-4 with ReduceLROnPlateau scheduling
- **Regularization**: Dropout (0.2), gradient clipping (max_norm=1.0)
- **Early stopping**: 20-epoch patience on validation loss
- **Normalization**: Yields normalized to [0, 1] scale

## üìÅ Project Structure

```
suzuki_reaction_engine/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_yield.py      # Dataset class and molecular featurization
‚îÇ   ‚îú‚îÄ‚îÄ model_yield.py         # GNN model architecture
‚îÇ   ‚îî‚îÄ‚îÄ train_yield.py         # Training script
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ suzuki_products.csv  # Processed reaction dataset
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îî‚îÄ‚îÄ README.md                  # This file
```

## üöÄ Installation

### Prerequisites

- Python 3.11 or 3.12 (PyTorch doesn't support 3.13 yet)
- CUDA 11.8+ (for GPU acceleration) or CPU
- NVIDIA GPU with CUDA support (recommended but not required)

### Step 1: Check Your Setup

```bash
# Check CUDA version (if you have an NVIDIA GPU)
nvidia-smi

# Check Python version
python --version
```

### Step 2: Create Virtual Environment

```bash
# Navigate to project directory
cd suzuki_reaction_engine

# Create virtual environment with Python 3.12
py -3.12 -m venv venv_cuda  # Windows
python3.12 -m venv venv_cuda  # Linux/Mac

# Activate environment
venv_cuda\Scripts\activate  # Windows
source venv_cuda/bin/activate  # Linux/Mac
```

### Step 3: Install PyTorch with CUDA

**For CUDA 12.1:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**For CUDA 11.8:**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**For CPU only:**
```bash
pip install torch torchvision torchaudio
```

### Step 4: Install Dependencies

```bash
pip install torch-geometric torch-scatter torch-sparse pandas rdkit scikit-learn
```

Or use requirements.txt:
```bash
pip install -r requirements.txt
```

### Step 5: Verify Installation

```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU mode\"}')"
```

## üíª Usage

### Training the Model

```bash
python src/train_yield.py
```

**Expected output:**
```
Using device: cuda
Dataset splits: Train=4032, Val=864, Test=864
Model parameters: 1,273,281

Epoch 1/100
  Train MSE (% scale): 245.32, RMSE: 15.66%
  Val MSE (% scale): 267.89, RMSE: 16.37%
  LR: 0.000500
  ‚úì New best model saved!

...

=== Final Test Results ===
Test MSE (% scale): 42.15
Test RMSE (% scale): 6.49%
Test MAE: 4.82%
Test R¬≤: 0.8734
Test MAPE (yields > 5%): 8.23%
```

### Customizing Training

Edit hyperparameters in `train_yield.py`:

```python
model = train_model(
    csv_path="data/processed/suzuki_products.csv",
    epochs=100,        # Number of training epochs
    batch_size=32,     # Batch size
    lr=5e-4,          # Initial learning rate
    device=device      # 'cuda' or 'cpu'
)
```

### Using the Trained Model

```python
import torch
from model_yield import SuzukiYieldGNN

# Load model
model = SuzukiYieldGNN(node_dim=22, edge_dim=6, cond_dim=32, hidden_dim=128)
checkpoint = torch.load('best_model.pt')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Make predictions
with torch.no_grad():
    prediction = model(data)  # data is a PyTorch Geometric Data object
    yield_percentage = prediction.item() * 100
    print(f"Predicted yield: {yield_percentage:.1f}%")
```

## üìö Dataset

The model is trained on Suzuki-Miyaura coupling reaction data with the following features:

### Required Columns in CSV:
- `reactant_1_smiles`: Aryl halide SMILES
- `reactant_2_smiles`: Boronic acid/ester SMILES
- `ligand_smiles`: Ligand SMILES
- `base_smiles`: Base SMILES
- `solvent_smiles`: Solvent SMILES
- `ligand_eq`: Ligand equivalents
- `base_eq`: Base equivalents
- `yield`: Reaction yield (0-100%)

### Data Source

Based on the [RXN Yields dataset](https://rxn4chemistry.github.io/rxn_yields/data/) for Suzuki-Miyaura reactions.

## üõ†Ô∏è Technical Details

### Molecular Featurization

**Atom Features (22 dimensions):**
- One-hot encoded atom type (H, B, C, N, O, F, P, S, Cl, Br, I, K, Na, Cs, Fe)
- Degree (normalized by 4)
- Formal charge (normalized by 2)
- Hybridization (normalized by 4)
- Aromaticity (binary)
- Atomic mass (normalized by 100)
- Ring membership (binary)

**Bond Features (6 dimensions):**
- Single bond (binary)
- Double bond (binary)
- Triple bond (binary)
- Aromatic bond (binary)
- Conjugated (binary)
- In ring (binary)

**Molecular Descriptors (10 per molecule √ó 3 molecules = 30 + 2 equivalents = 32 total):**
- Molecular weight
- LogP (lipophilicity)
- H-bond donors/acceptors
- TPSA (topological polar surface area)
- Rotatable bonds
- Ring count
- Aromatic ring count
- Heteroatom count
- Fraction of sp3 carbons

## üîß Troubleshooting

### Common Issues

**Issue: "CUDA out of memory"**
```python
# Reduce batch size in train_yield.py
batch_size=16  # or 8
```

**Issue: "RuntimeError: mat1 and mat2 shapes cannot be multiplied"**
- Ensure conditions are 2D tensors with `.unsqueeze(0)` in `dataset_yield.py`
- Verify `cond_dim` calculation uses `sample.conditions.shape[1]`

**Issue: Training on CPU is slow**
- Install Python 3.12 and PyTorch with CUDA support
- Reduce batch size and epochs for faster testing
- Consider using a GPU instance on cloud platforms (Google Colab, AWS)

**Issue: "AttributeError: FractionCsp3"**
- Change to `FractionCSP3` (uppercase) in `dataset_yield.py`

## üìà Performance Optimization

### For Faster Training:
1. Use GPU (30-50x faster than CPU)
2. Increase batch size (if GPU memory allows): `batch_size=64`
3. Use mixed precision training (add to future version)

### For Better Accuracy:
1. Increase model capacity: `hidden_dim=256`
2. Add more GATv2 layers
3. Tune learning rate: try `lr=1e-4` or `lr=1e-3`
4. Increase training epochs: `epochs=150`
5. Data augmentation: SMILES randomization

## ü§ù Contributing

Contributions are welcome! Areas for improvement:

- [ ] Add SMILES augmentation for better generalization
- [ ] Implement mixed precision training (FP16)
- [ ] Add hyperparameter search (Optuna/Ray Tune)
- [ ] Extend to other cross-coupling reactions
- [ ] Add uncertainty quantification
- [ ] Web interface for predictions
- [ ] Docker containerization

## üìÑ License

This project is licensed under the MIT License.

## üôè Acknowledgments

- **RXN4Chemistry** for the Suzuki-Miyaura reaction dataset
- **PyTorch Geometric** for graph neural network tools
- **RDKit** for molecular informatics
- **Graph Attention Networks** (Veliƒçkoviƒá et al., 2018)
- **GATv2** (Brody et al., 2021)

## üìß Contact

For questions or collaborations, please open an issue on GitHub.

---

**Built with ‚ù§Ô∏è for computational chemistry and machine learning**
